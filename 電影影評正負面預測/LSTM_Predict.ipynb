{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import model_from_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_tags(text):\n",
    "    re_tag = re.compile(r'<[^>]+>')\n",
    "    return re_tag.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(filetype):\n",
    "    path = \"dataset/\"\n",
    "    file_list = []\n",
    "\n",
    "    postive_path = path + filetype + \"/pos/\"\n",
    "    for f in os.listdir(postive_path):\n",
    "        file_list += [postive_path + f]\n",
    "    \n",
    "    negative_path = path + filetype + \"/neg/\"\n",
    "    for f in os.listdir(negative_path):\n",
    "        file_list += [negative_path + f]\n",
    "\n",
    "    print('read', filetype, 'files:', len(file_list))\n",
    "\n",
    "    if filetype == 'train':\n",
    "        all_labels = ([1] * 12000 + [0] * 12000)\n",
    "    else:\n",
    "        all_labels = ([1] * 500 + [0] * 500)\n",
    "\n",
    "    all_texts = []\n",
    "    for fi in file_list:\n",
    "        with open(fi, encoding = 'utf8') as file_input:\n",
    "            all_texts += [rm_tags(\" \".join(file_input.readlines()))]\n",
    "\n",
    "    return all_labels, all_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_predict(input_text, input_List, x_test, y_test):\n",
    "    with open('lstm_data/lstm.yml', 'r') as f:\n",
    "        yaml_string = yaml.load(f)\n",
    "    model = model_from_yaml(yaml_string)\n",
    "    model.load_weights('lstm_data/lstm.h5')\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
    "    score = model.evaluate(x_test, y_test, verbose = 1, batch_size = 1024)\n",
    "    print('準確度 : ' + str(score[1]))\n",
    "        \n",
    "    with open('output.csv', 'w+') as new_csv:\n",
    "        pass\n",
    "        \n",
    "    csv_lst = []\n",
    "    i = 0\n",
    "    for item in input_List:\n",
    "        i += 1\n",
    "        predict_result = model.predict_classes(item)\n",
    "        csv_lst.append([i, sensitive_dict(predict_result[0][0])])\n",
    "        \n",
    "    df = pd.DataFrame(data=csv_lst, columns=['Id', 'Label'])\n",
    "    df = df.append(df, ignore_index=False)\n",
    "    df.to_csv('output.csv', sep=',', encoding='utf_8_sig', index=False)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitive_dict(postive):\n",
    "    if int(postive) == 1:\n",
    "        return 'pos'\n",
    "    else:\n",
    "        return 'neg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read train files: 24000\n",
      "read test files: 1000\n",
      "-------------------------------------------------------------\n",
      "Start Predicting................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 406us/step\n",
      "準確度 : 0.8389999866485596\n",
      "-------------------------------------------------------------\n",
      "All Finish!................................................\n"
     ]
    }
   ],
   "source": [
    "y_train, train_text = read_files(\"train\")\n",
    "y_test, test_text = read_files(\"test\")\n",
    "token = Tokenizer(num_words = 1000)\n",
    "token.fit_on_texts(train_text)\n",
    "\n",
    "x_train_seq = token.texts_to_sequences(train_text)\n",
    "x_test_seq = token.texts_to_sequences(test_text)\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train_seq, maxlen = 300)\n",
    "x_test = sequence.pad_sequences(x_test_seq, maxlen = 300)\n",
    "\n",
    "df = pd.read_csv('test_dataset.csv', header = None)\n",
    "df = pd.DataFrame(df[1].astype(str))\n",
    "input_lst = []\n",
    "\n",
    "for data in df[1]:\n",
    "    data = data.replace('[換行字元]', '\\n')\n",
    "    input_seq = token.texts_to_sequences([data])\n",
    "    pad_input_seq = sequence.pad_sequences(input_seq, maxlen = 300)\n",
    "    input_lst.append(pad_input_seq)\n",
    "\n",
    "print('-------------------------------------------------------------')\n",
    "print('Start Predicting................................................')\n",
    "lstm_predict(df[1], input_lst, x_test, y_test)\n",
    "print('-------------------------------------------------------------')\n",
    "print('All Finish!................................................')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
