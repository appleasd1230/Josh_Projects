{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import yaml\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import model_from_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters:\n",
    "batch_size = 1024\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_tags(text):\n",
    "    re_tag = re.compile(r'<[^>]+>')\n",
    "    return re_tag.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(filetype):\n",
    "    path = \"dataset/\"\n",
    "    file_list = []\n",
    "\n",
    "    postive_path = path + filetype + \"/pos/\"\n",
    "    for f in os.listdir(postive_path):\n",
    "        file_list += [postive_path + f]\n",
    "    \n",
    "    negative_path = path + filetype + \"/neg/\"\n",
    "    for f in os.listdir(negative_path):\n",
    "        file_list += [negative_path + f]\n",
    "\n",
    "    print('read', filetype, 'files:', len(file_list))\n",
    "    \n",
    "    if filetype == 'train':\n",
    "        all_labels = ([1] * 12000 + [0] * 12000)\n",
    "    else:\n",
    "        all_labels = ([1] * 500 + [0] * 500)\n",
    "        \n",
    "    all_texts = []\n",
    "    for fi in file_list:\n",
    "        with open(fi, encoding = 'utf8') as file_input:\n",
    "            all_texts += [rm_tags(\" \".join(file_input.readlines()))]\n",
    "\n",
    "    return all_labels, all_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(x_train, y_train, x_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(output_dim = 64,\n",
    "                        input_dim = 1000,\n",
    "                        input_length = 300))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(units = 64,\n",
    "                    activation = 'relu'))      \n",
    "    model.add(LSTM(32))\n",
    "    model.add(Dense(units = 128,\n",
    "                    activation = 'relu'))                    \n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(units = 64,\n",
    "                    activation = 'relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(units = 32,\n",
    "                    activation = 'relu'))    \n",
    "    model.add(Dropout(0.4))    \n",
    "    model.add(Dense(units = 1,\n",
    "                    activation = 'sigmoid'))\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])               \n",
    "    model.summary()\n",
    "    model.fit(x_train, y_train, batch_size = batch_size, epochs = epochs, verbose = 2, validation_split = 0.2)\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, verbose = 1, batch_size = batch_size)\n",
    "    print(score[1])\n",
    "\n",
    "    yaml_string = model.to_yaml()\n",
    "    with open('lstm_data/lstm.yml', 'w') as outfile:\n",
    "        outfile.write(yaml.dump(yaml_string, default_flow_style=True))\n",
    "    model.save_weights('lstm_data/lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitive_dict(postive):\n",
    "    if int(postive) == '1':\n",
    "        return '正向'\n",
    "    else:\n",
    "        return '負向'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read train files: 24000\n",
      "read test files: 1000\n",
      "-------------------------------------------------------------\n",
      "Start Training................................................\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 300, 64)           64000     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300, 64)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300, 64)           4160      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 95,169\n",
      "Trainable params: 95,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19200 samples, validate on 4800 samples\n",
      "Epoch 1/30\n",
      " - 27s - loss: 0.6827 - accuracy: 0.6027 - val_loss: 0.9479 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      " - 27s - loss: 0.6629 - accuracy: 0.6243 - val_loss: 0.9567 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      " - 28s - loss: 0.6304 - accuracy: 0.6248 - val_loss: 0.9508 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      " - 29s - loss: 0.5683 - accuracy: 0.6812 - val_loss: 0.7698 - val_accuracy: 0.6452\n",
      "Epoch 5/30\n",
      " - 30s - loss: 0.4749 - accuracy: 0.7857 - val_loss: 0.7312 - val_accuracy: 0.6727\n",
      "Epoch 6/30\n",
      " - 34s - loss: 0.4028 - accuracy: 0.8314 - val_loss: 0.4560 - val_accuracy: 0.8062\n",
      "Epoch 7/30\n",
      " - 36s - loss: 0.3716 - accuracy: 0.8478 - val_loss: 0.3532 - val_accuracy: 0.8544\n",
      "Epoch 8/30\n",
      " - 36s - loss: 0.3570 - accuracy: 0.8566 - val_loss: 0.4446 - val_accuracy: 0.8175\n",
      "Epoch 9/30\n",
      " - 37s - loss: 0.3385 - accuracy: 0.8682 - val_loss: 0.4045 - val_accuracy: 0.8429\n",
      "Epoch 10/30\n",
      " - 38s - loss: 0.3159 - accuracy: 0.8784 - val_loss: 0.3516 - val_accuracy: 0.8587\n",
      "Epoch 11/30\n",
      " - 38s - loss: 0.3018 - accuracy: 0.8824 - val_loss: 0.3327 - val_accuracy: 0.8675\n",
      "Epoch 12/30\n",
      " - 39s - loss: 0.2967 - accuracy: 0.8868 - val_loss: 0.2998 - val_accuracy: 0.8865\n",
      "Epoch 13/30\n",
      " - 38s - loss: 0.2913 - accuracy: 0.8833 - val_loss: 0.3623 - val_accuracy: 0.8546\n",
      "Epoch 14/30\n",
      " - 38s - loss: 0.2937 - accuracy: 0.8837 - val_loss: 0.3314 - val_accuracy: 0.8719\n",
      "Epoch 15/30\n",
      " - 39s - loss: 0.2869 - accuracy: 0.8888 - val_loss: 0.3395 - val_accuracy: 0.8604\n",
      "Epoch 16/30\n",
      " - 39s - loss: 0.2868 - accuracy: 0.8877 - val_loss: 0.3352 - val_accuracy: 0.8733\n",
      "Epoch 17/30\n",
      " - 38s - loss: 0.2836 - accuracy: 0.8886 - val_loss: 0.3664 - val_accuracy: 0.8406\n",
      "Epoch 18/30\n",
      " - 38s - loss: 0.2787 - accuracy: 0.8892 - val_loss: 0.3730 - val_accuracy: 0.8469\n",
      "Epoch 19/30\n",
      " - 39s - loss: 0.2786 - accuracy: 0.8910 - val_loss: 0.3669 - val_accuracy: 0.8460\n",
      "Epoch 20/30\n",
      " - 39s - loss: 0.2759 - accuracy: 0.8923 - val_loss: 0.4091 - val_accuracy: 0.8375\n",
      "Epoch 21/30\n",
      " - 38s - loss: 0.2748 - accuracy: 0.8919 - val_loss: 0.2720 - val_accuracy: 0.8888\n",
      "Epoch 22/30\n",
      " - 38s - loss: 0.2812 - accuracy: 0.8884 - val_loss: 0.4279 - val_accuracy: 0.8246\n",
      "Epoch 23/30\n",
      " - 38s - loss: 0.2731 - accuracy: 0.8924 - val_loss: 0.3490 - val_accuracy: 0.8554\n",
      "Epoch 24/30\n",
      " - 38s - loss: 0.2678 - accuracy: 0.8945 - val_loss: 0.4159 - val_accuracy: 0.8344\n",
      "Epoch 25/30\n",
      " - 40s - loss: 0.2672 - accuracy: 0.8925 - val_loss: 0.3348 - val_accuracy: 0.8715\n",
      "Epoch 26/30\n",
      " - 39s - loss: 0.2641 - accuracy: 0.8953 - val_loss: 0.4205 - val_accuracy: 0.8360\n",
      "Epoch 27/30\n",
      " - 38s - loss: 0.2632 - accuracy: 0.8942 - val_loss: 0.4586 - val_accuracy: 0.8277\n",
      "Epoch 28/30\n",
      " - 39s - loss: 0.2634 - accuracy: 0.8940 - val_loss: 0.3641 - val_accuracy: 0.8500\n",
      "Epoch 29/30\n",
      " - 38s - loss: 0.2533 - accuracy: 0.8960 - val_loss: 0.3006 - val_accuracy: 0.8790\n",
      "Epoch 30/30\n",
      " - 37s - loss: 0.2563 - accuracy: 0.8946 - val_loss: 0.3128 - val_accuracy: 0.8719\n",
      "1000/1000 [==============================] - 0s 428us/step\n",
      "0.8389999866485596\n",
      "-------------------------------------------------------------\n",
      "All Finish!................................................\n"
     ]
    }
   ],
   "source": [
    "y_train, train_text = read_files(\"train\")\n",
    "y_test, test_text = read_files(\"test\")\n",
    "token = Tokenizer(num_words = 1000)\n",
    "token.fit_on_texts(train_text)\n",
    "\n",
    "x_train_seq = token.texts_to_sequences(train_text)\n",
    "x_test_seq = token.texts_to_sequences(test_text)\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train_seq, maxlen = 300)\n",
    "x_test = sequence.pad_sequences(x_test_seq, maxlen = 300)\n",
    "\n",
    "print('-------------------------------------------------------------')\n",
    "print('Start Training................................................')\n",
    "model_training(x_train, y_train, x_test, y_test)\n",
    "print('-------------------------------------------------------------')\n",
    "print('All Finish!................................................')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
